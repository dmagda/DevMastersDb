{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-powered SQL Agent With LangChain for SQL Databases\n",
    "\n",
    "Learn new tech by building a simple AI-powered SQL agent for your favorite SQL database.\n",
    "\n",
    "This agent utilizes LangChain to create a flow that takes user questions in plain English, then uses an LLM (Large Language Model) to generate a SQL request. It executes the request on your database and then uses the LLM again to respond as a human would, or to convert the response into a JSON object for your downstream APIs.\n",
    "\n",
    "[![@DevMastersDB](https://github.com/dmagda/DevMastersDb/assets/1537233/5cfcd07d-3f4b-4216-a166-e8036de1f8b3)](https://youtu.be/SWr9w96iBnM)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* [Docker](https://www.docker.com)\n",
    "* Python and pip.\n",
    "* [OpenAI API key](https://platform.openai.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment\n",
    "\n",
    "Use pip to install required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install psycopg2 langchain langchain_openai langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a Postgres instance in Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for Postgres to be ready\n",
    "! while ! docker exec -it postgres-demo-instance pg_isready -U postgres; do sleep 1; done\n",
    "\n",
    "# Copy the schema and data files to the container\n",
    "! docker cp ./schema.sql postgres-demo-instance:/home\n",
    "! docker cp ./data.sql postgres-demo-instance:/home\n",
    "\n",
    "# Load the dataset into the database\n",
    "! docker exec -it postgres-demo-instance psql -U postgres -c '\\i /home/schema.sql'\n",
    "! docker exec -it postgres-demo-instance psql -U postgres -c '\\i /home/data.sql'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide OpenAI API Key\n",
    "\n",
    "Provide your OpenAI API key by setting it as the `OPENAI_API_KEY` environment variable and run the code snippet below. If the variable is not set, you'll be prompted to enter the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if (openai_key == None):\n",
    "    openai_key = getpass('Provide your OpenAI API key: ')\n",
    "\n",
    "if (not openai_key):\n",
    "    raise Exception('No OpenAI API key provided. Please set the OPENAI_API_KEY environment variable or provide it when prompted.')\n",
    "\n",
    "print('OpenAI API key set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Postgres With SQL Agent\n",
    "\n",
    "Prepare a system prompt that defines SQL agent's behavior and clarifes the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_agent_prompt(input_text):\n",
    "    agent_prompt = f\"\"\"\n",
    "    Query the database using PostgreSQL syntax.\n",
    "\n",
    "    Use the shoe_color enum to query the color. Do not query this column with any values not found in the shoe_color enum.\n",
    "    Use the shoe_width enum to query the width. Do not query this column with any values not found in the shoe_width enum.\n",
    "\n",
    "    The color and width columns are array types. The name column is of type VARCHAR.\n",
    "    An example query using an array columns would be:\n",
    "    SELECT * FROM products, unnest(color) as col WHERE col::text % SOME_COLOR;\n",
    "    or\n",
    "    SELECT * FROM products, unnest(width) as wid WHERE wid::text % SOME_WIDTH;\n",
    "\n",
    "    An example query using the name column would be:\n",
    "    select * from products where name ILIKE '%input_text%';\n",
    "\n",
    "    It is not necessary to search on all columns, only those necessary for a query. \n",
    "    \n",
    "    Generate a PostgreSQL query using the input: {input_text}. \n",
    "    \n",
    "    Answer needs to be in the format of a JSON object. \n",
    "    This object needs to have the key \"query\" with the SQL query and \"query_response\" as a JSON array of the query response.\n",
    "    \"\"\"\n",
    "\n",
    "    return agent_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LangChain's OpenAI and SQL agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "# Initialize the OpenAI's agent\n",
    "openai = OpenAI(\n",
    "    api_key=openai_key,\n",
    "    temperature=0, # the model's creativity. 0 = deterministic output with minimal creativity. 1 = very diverse and creative.\n",
    "    max_tokens=-1 # the maximum number of tokens to generate in the completion. -1 returns as many tokens as possible given the prompt and the models maximal context size\n",
    "    )\n",
    "\n",
    "# Initialize LangChain's database agent\n",
    "database = SQLDatabase.from_uri(\n",
    "    \"postgresql+psycopg2://sql_agent:password@localhost:5432/postgres\", \n",
    "    include_tables=[\"products\", \"users\", \"purchases\", \"product_inventory\"]);\n",
    "\n",
    "# Initialize LangChain's database chain agent\n",
    "db_chain = SQLDatabaseChain.from_llm(openai, db=database, verbose=True, use_query_checker=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the SQL agent by running the code snippet below and asking the following questions (one at a time): \n",
    "\n",
    "* What are the most popular products?\n",
    "* What purchases have been made by user1?\n",
    "* What colors do the Intelligent Racer come in?\n",
    "* How many narrow shoes come in pink?\n",
    "* Find me shoes that are in stock and available in size 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt=input(\"Ask a question: \")\n",
    "agent_prompt = prepare_agent_prompt(user_prompt)\n",
    "\n",
    "try:\n",
    "    result = db_chain.invoke(agent_prompt)\n",
    "\n",
    "    print(f\"Answer: {result['result']}\")\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
